{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "sHNZLFyJtZ9t"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: SpeechRecognition in c:\\users\\playdata\\appdata\\local\\anaconda3\\envs\\llm_env\\lib\\site-packages (3.14.3)\n",
            "Requirement already satisfied: typing-extensions in c:\\users\\playdata\\appdata\\local\\anaconda3\\envs\\llm_env\\lib\\site-packages (from SpeechRecognition) (4.15.0)\n",
            "Note: you may need to restart the kernel to use updated packages.\n",
            "Requirement already satisfied: gtts in c:\\users\\playdata\\appdata\\local\\anaconda3\\envs\\llm_env\\lib\\site-packages (2.5.4)\n",
            "Requirement already satisfied: requests<3,>=2.27 in c:\\users\\playdata\\appdata\\local\\anaconda3\\envs\\llm_env\\lib\\site-packages (from gtts) (2.32.5)\n",
            "Requirement already satisfied: click<8.2,>=7.1 in c:\\users\\playdata\\appdata\\local\\anaconda3\\envs\\llm_env\\lib\\site-packages (from gtts) (8.1.8)\n",
            "Requirement already satisfied: colorama in c:\\users\\playdata\\appdata\\local\\anaconda3\\envs\\llm_env\\lib\\site-packages (from click<8.2,>=7.1->gtts) (0.4.6)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\playdata\\appdata\\local\\anaconda3\\envs\\llm_env\\lib\\site-packages (from requests<3,>=2.27->gtts) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\playdata\\appdata\\local\\anaconda3\\envs\\llm_env\\lib\\site-packages (from requests<3,>=2.27->gtts) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\playdata\\appdata\\local\\anaconda3\\envs\\llm_env\\lib\\site-packages (from requests<3,>=2.27->gtts) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\playdata\\appdata\\local\\anaconda3\\envs\\llm_env\\lib\\site-packages (from requests<3,>=2.27->gtts) (2025.8.3)\n",
            "Note: you may need to restart the kernel to use updated packages.\n",
            "Requirement already satisfied: PyAudio in c:\\users\\playdata\\appdata\\local\\anaconda3\\envs\\llm_env\\lib\\site-packages (0.2.14)\n",
            "Note: you may need to restart the kernel to use updated packages.\n",
            "Requirement already satisfied: pygame in c:\\users\\playdata\\appdata\\local\\anaconda3\\envs\\llm_env\\lib\\site-packages (2.6.1)\n"
          ]
        }
      ],
      "source": [
        "# %pip install SpeechRecognition\n",
        "# %pip install gtts\n",
        "# %pip install PyAudio\n",
        "# %pip install pygame"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "QqWEH1y9lVoO"
      },
      "outputs": [],
      "source": [
        "from openai import OpenAI\n",
        "from gtts import gTTS\n",
        "from io import BytesIO\n",
        "import pygame, os\n",
        "import speech_recognition as sr\n",
        "\n",
        "# from google.colab import userdata\n",
        "# GPT_API_KEY = userdata.get('GPT_API_KEY')\n",
        "# client = OpenAI(api_key=GPT_API_KEY)\n",
        "\n",
        "from dotenv import load_dotenv\n",
        "load_dotenv()\n",
        "OPEN_API_KEY = os.getenv('OPEN_API_KEY')\n",
        "client = OpenAI()\n",
        "\n",
        "mp3_fp = BytesIO()\n",
        "recognizer = sr.Recognizer()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 음성 출력\n",
        "def speak(text):\n",
        "    if not pygame.mixer.get_init():\n",
        "        pygame.mixer.init()\n",
        "\n",
        "    mp3_fp = BytesIO()\n",
        "    tts = gTTS(text, lang=\"ko\")\n",
        "    tts.write_to_fp(mp3_fp)\n",
        "\n",
        "    mp3_fp.seek(0)\n",
        "    pygame.mixer.music.load(mp3_fp, \"mp3\")\n",
        "    pygame.mixer.music.play()\n",
        "\n",
        "    # 끝날 때까지 대기\n",
        "    while pygame.mixer.music.get_busy():\n",
        "        pygame.time.Clock().tick(10)\n",
        "\n",
        "    mp3_fp.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [],
      "source": [
        "speak('테스트')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7hnEOn3mCLvG",
        "outputId": "dc4467c7-478e-4c8d-cc1c-59a274d025e7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "AI: 재료로는 파스타 면 200그램, 올리브유 2큰술, 마늘 2쪽, 방울토마토 200그램, 바질 약간, 소금과 후추가 필요합니다.\n"
          ]
        }
      ],
      "source": [
        "content = \"\"\"\n",
        "    당신은 사용자의 요리 도우미 AI입니다.\n",
        "    사용자가 요청하는 요리의 레시피(재료, 조리법, 예상 소요 시간 포함)를 제공하고,\n",
        "    요리 과정 중에 생기는 질문에 친절하게 답변하며,\n",
        "    특정 재료를 대체할 수 있는 방법을 알려주는 역할을 수행합니다.\n",
        "    답변은 - , : 등 특수문자를 사용하지 말고 사람이 말하듯이 답변 하세요.\n",
        "    그리고 모두 한국어로 대답하세요. 예시) g → 그램\n",
        "    재료 준비과정, 조리과정 전부 단계별로 한개씩만 답변하세요.\n",
        "    재료 소개를 했으면 답변 종료입니다.\n",
        "    재료 준비나 조리법도 한 단계가 끝났으면 동일하게 답변 종료입니다.\n",
        "    준비과정이나 조리 과정을 한 번에 답변하지 마세요. 무조건 한 단계씩만 답변합니다.\n",
        "\n",
        "    예시1 : 재료로는 돼지고기 200그람, 김치 반포기, 두부 한 모, 물 등이 필요합니다.\n",
        "    예시2 : 우선 김치를 한 입 크기로 잘라줍니다.\n",
        "\"\"\"\n",
        "\n",
        "messages = [{\"role\": \"system\", \"content\": content}]\n",
        "\n",
        "while True:\n",
        "    # with sr.Microphone() as source:\n",
        "        # print('말씀하세요.')\n",
        "        # audio = recognizer.listen(source)\n",
        "        # txt = recognizer.recognize_google(audio, language='ko-KR')\n",
        "        # print(txt)\n",
        "\n",
        "        # 테스트용 사용자로부터 직접 입력 받음\n",
        "        txt = input(\"텍스트를 입력: \")\n",
        "\n",
        "        if txt == '종료':\n",
        "            break\n",
        "\n",
        "        messages.append({\"role\": \"user\", \"content\": txt})\n",
        "        response = client.chat.completions.create(\n",
        "            model=\"gpt-4o-mini\",\n",
        "            messages=messages,\n",
        "            temperature=0.5,\n",
        "            max_tokens=4096,\n",
        "            top_p=1\n",
        "        )\n",
        "        assistant_response_text = response.choices[0].message.content\n",
        "        messages.append({\"role\": \"assistant\", \"content\": assistant_response_text})\n",
        "\n",
        "        print(\"AI:\", assistant_response_text) # AI 응답도 구분하여 출력하도록 수정\n",
        "        speak(assistant_response_text)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "llm_env",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
